{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A look into Lucene Scoring functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apache Lucene is a Java library used for the full text search of documents, and is at the core of search servers such as [Solr](http://lucene.apache.org/solr/) and [Elasticsearch](https://www.elastic.co/products/elasticsearch).\n",
    "\n",
    "In a nutshell, Lucene allows you to run a query against a set of documents and receive back a ranked result of the documents, each with a score calculated based on how similar the document matched the original query.\n",
    "\n",
    "In this Notebook I have rewritten in Python the two most important similarities as they are implemented by Lucene:\n",
    "* The **BM25**, which has become the default similarity from Lucene 6 (released in April 2016)\n",
    "* The **TF-IDF**, the classical similarity used in information retriavial which was the default similarity in Lucene up to version 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classic Lucene Similarity: a modified TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In information retrieval, [**tf–idf**](https://en.wikipedia.org/wiki/Tf%E2%80%93idf), short for **term frequency–inverse document frequency**, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.\n",
    "\n",
    "Lucene's Practical Scoring Function uses a modified version of the TF-IDF found in textbooks, which is explained below. \n",
    "\n",
    "### Lucene modified TF\n",
    "\n",
    "Instead of taking the Term Frequency as is, Lucene uses $\\sqrt{TF}$. The TF score is computed as follows:\n",
    "\n",
    "| TF | Lucene TF |\n",
    "|------|------|\n",
    "|   1  | 1 |\n",
    "|   2  | 1.414 |\n",
    "|   4  | 2 |\n",
    "|   8  | 2.828 |\n",
    "|   16  | 4 |\n",
    "\n",
    "This way, documents with twice the number of terms as another document aren’t twice as relevant.\n",
    "\n",
    "### Lucene modified IDF\n",
    "\n",
    "Similarly users don’t consider terms that only occur in 10 documents ten times as special as those that occur in 100 documents. Instead, the IDF score is computed as:\n",
    "\n",
    "$$ln\\left ( \\frac{docCount}{docFreq_{t} + 1} \\right ) + 1$$\n",
    "\n",
    "where *docCount* is the total number of documents in the collection, and *docFreq<sub>t</sub>* is the number of documents in the collection containing  term *t*.\n",
    "\n",
    "### Document length\n",
    "\n",
    "The impact of a document’s length is taken into account by multiplying the TF\\*IDF score by $\\frac{1}{\\sqrt{|d|}}$\n",
    "\n",
    "\n",
    "### Lucene Practical Scoring Function\n",
    "\n",
    "Combinining the pieces together and normalising, Lucene's Practical Scoring Function (simplified version) is as follows: \n",
    "\n",
    "$$score_{q,\\; d}   =   coord_{q, d} \\;  \\times \\;  queryNorm_{q} \\;  \\times \\; \\sum_{t\\;  in\\; q} \\left ( tf_{t, d}\\;  \\times \\; idf_{t}^{2} \\;  \\times \\;  norm_{d}  \\right )$$\n",
    "\n",
    "where:\n",
    "\n",
    "* **coord<sub>q, d</sub>** : is a score factor based on how many of the query terms are found in the specified document. For example, if documnt *d* contains 2 of the 3 terms of query *q*, then coord<sub>q, d</sub> is 2/3.\n",
    "* **queryNorm<sub>q</sub>** : is a normalizing factor used to make scores between queries comparable. This factor does not affect document ranking (since all ranked documents are multiplied by the same factor), but rather just attempts to make scores from different queries (or even different indexes) comparable. The default computation produces a Euclidean norm:\n",
    "\n",
    "$$ queryNorm_{q} =\\frac{1}{\\sqrt{sumOfSquaredWeights}}   $$\n",
    "\n",
    "    where\n",
    "\n",
    "$$ sumOfSquaredWeights = \\sum_{t \\; in \\; q} idf_{t}^{2} $$\n",
    "\n",
    "* **tf<sub>t, d</sub>**: correlates to the term's frequency, defined as the number of times term t appears in the currently scored document d. Documents that have more occurrences of a given term receive a higher score. It is computed as explained above.\n",
    "\n",
    "* **idf<sub>t</sub>** : stands for Inverse Document Frequency. This value correlates to the inverse of docFreq (the number of documents in which the term t appears). This means rarer terms give higher contribution to the total score. idf<sub>t</sub> appears for t in both the query and the document, hence it is squared in the equation. It is computed as explained above.\n",
    "\n",
    "* **norm<sub>d</sub>** : encapsulates a (indexing time) length factor computed and stored as an 8 bit floating point value which causes some loss of precison (lossy compression).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. New Lucene Default Similarity: BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BM25 stands for [**Best Matching 25**](https://en.wikipedia.org/wiki/Okapi_BM25), also called *Okapi weighting scheme*, and improves upon the classical TF \\* IDF.\n",
    "\n",
    "Released in [1994](http://trec.nist.gov/pubs/trec3/t3_proceedings.html), BM25 has its roots in [probabilistic information retrieval](http://nlp.stanford.edu/IR-book/html/htmledition/probabilistic-information-retrieval-1.html). A relevance score, according to probabilistic information retrieval, reflects the probability a user will consider the result relevant. \n",
    "\n",
    "The [BM25 weighting scheme](https://github.com/apache/lucene-solr/blob/master/lucene/core/src/java/org/apache/lucene/search/similarities/BM25Similarity.java) has become the default similarity measure from **Lucene 6**.\n",
    "\n",
    "### Lucene BM25 view of IDF\n",
    "\n",
    "The [original BM25 formula for IDF](https://en.wikipedia.org/wiki/Okapi_BM25#The_ranking_function) is computed as:\n",
    "\n",
    "$$idf_{t} = \\ln (\\frac{docCount - docFreq_{t} + 0.5}{docFreq_{t} + 0.5})$$\n",
    "\n",
    "where *docCount* is the total number of documents in the collection, and *docFreq<sub>t</sub>* is the number of documents in the collection containing  term *t*.\n",
    "\n",
    "It shows potentially major drawbacks when using it for terms appearing in more than half of the corpus documents. These terms' IDF is negative, so for any two almost-identical documents, one which contains the term and one which does not contain it, the latter will possibly get a larger score. This means that terms appearing in more than half of the corpus will provide negative contributions to the final document score. This is often an undesirable behavior, so Lucene overcomes this problem by adding 1 to the value, before taking the log, which makes it impossible to compute a negative value.\n",
    "\n",
    "$$idf_{t} = \\ln (1 + \\frac{docCount - docFreq_{t} + 0.5}{docFreq_{t} + 0.5})$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Lucene BM25 view of TF and the influence of docLength\n",
    "\n",
    "Term frequency in BM25 lower the impact of term frequency even further than traditional TF \\* IDF. In the BM25, the impact of term frequency is always increasing, but asymptotically approaches the value (k + 1) (where in the default implementation k = 1.2).\n",
    "\n",
    "$$ \\frac{(k + 1) \\times tf_{t, d}}{k + tf_{t, d}} $$\n",
    "\n",
    "More *tf* always means more relevance. However in this way it quickly hits diminishing returns. Classic *tf*, on the other hand, constantly increases and never reaches a saturation point.\n",
    "\n",
    "Changing k can be a useful tuning approach to modify the impact of the *tf*. A higher k causes *tf* to take longer to reach saturation. By stretching out the point of saturation, it stretches out the relevance difference between higher and lower term frequency docs.\n",
    "\n",
    "The TF score above is further influenced by whether the document length is above or below the average length of a document in the corpus.\n",
    "The formula above is modified by adding (1.0 - b + b * L) as a multiple on k in the denominator.\n",
    "\n",
    "$$ tfNorm_{t,\\; d} =  \\frac{(k + 1) \\times  tf_{t, d}}{k \\times  (1.0 - b + b \\times  L) + tf_{t, d}} $$\n",
    "\n",
    "Here L is how long a document is relative to the average document length. L therefore is actually presented as $ \\frac{|d|}{avgDocumentLength} $, i.e. this document length divided by the average document length.\n",
    "\n",
    "The constant b (where in the default implementation b = 0.75) allows to finely tune how much influence the L value has on scoring. A b of 0 completely removes the influence of L. A higher b adds more document length influence on the scoring. \n",
    "\n",
    "### All Together\n",
    "\n",
    "Putting all together, the score of a document *d* given a query *q* (with multiple terms) is given by:\n",
    "\n",
    "$$ score_{q,\\; d} = \\sum_{t\\; in \\; q }tfNorm_{t,\\; d} \\times  idf_{t} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A note on Lucene Lossy Compression\n",
    "\n",
    "Lucene computes the lenght of a document |d| at indexing time, i.e. every time a document is added to the index. This information is then retrieved at search time, i.e. when the query is performed. \n",
    "\n",
    "However, to efficiently store this information, Lucene performs a lossy compression. The document length value is encoded as a single byte before being stored. At search time, the byte value is read from the index directory and decoded back to a float value. This encoding/decoding, while reducing index size, comes with the price of precision loss, i.e. it is not guaranteed that $decode( encode(x) ) = x$.\n",
    "\n",
    "The rationale supporting such lossy compression is that given the difficulty (and inaccuracy) of users to express their true information need by a query, only big differences matter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import struct\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implement encoding and decoding function for the lossy compression, as done here \n",
    "# https://github.com/apache/lucene-solr/blob/master/lucene/core/src/java/org/apache/lucene/util/SmallFloat.java\n",
    "def floatToRawIntBits(f):\n",
    "    s = struct.pack('=f', f)\n",
    "    return struct.unpack('=l', s)[0]\n",
    "\n",
    "def intBitsToFloat(b):\n",
    "    s = struct.pack('>l', b)\n",
    "    return struct.unpack('>f', s)[0]\n",
    "\n",
    "def byte315ToFloat(b):\n",
    "    if (b == 0):\n",
    "        return 0.0\n",
    "    bits = (b&0xff) << (24-3)\n",
    "    bits += (63-15) << 24\n",
    "    return intBitsToFloat(bits)\n",
    "\n",
    "def floatToByte315(f):\n",
    "    bits = floatToRawIntBits(f)\n",
    "    \n",
    "    smallfloat = bits >> (24-3)\n",
    "    \n",
    "    if (smallfloat <= ((63-15)<<3)):\n",
    "        return  bytes(0) if (bits<=0) else bytes(1)\n",
    "    \n",
    "    if (smallfloat >= ((63-15)<<3) + 0x100):\n",
    "        return -1\n",
    "    \n",
    "    return int(bytes(smallfloat - ((63-15)<<3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Similarity(object):\n",
    "    def __init__(self): \n",
    "        self.NORM_TABLE = np.arange(256, dtype= float)\n",
    "    \n",
    "    def decodeNormValue(self, b):\n",
    "        return self.NORM_TABLE[b & 0xFF] # & 0xFF maps negative bytes to positive above 127\n",
    "    \n",
    "    def encodeNormValue(self, value):\n",
    "        pass\n",
    "    \n",
    "    def get_idf(self, docCount, docFreqs):\n",
    "        pass\n",
    "    \n",
    "    def get_tf(self, docs, query):\n",
    "        vect = CountVectorizer(vocabulary = query, analyzer='word')\n",
    "        tf = vect.fit_transform(docs)\n",
    "        docCount = tf.shape[0]\n",
    "        docFreqs = (tf != 0).sum(0)\n",
    "        return (tf, docCount, docFreqs)\n",
    "    \n",
    "    def execute(self, query, docs):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, value):\n",
    "        pass\n",
    "    \n",
    "    def get_coord(self, tf, idf):\n",
    "        nTerms = tf.shape[1]\n",
    "        return np.divide((tf != 0).astype(float)*(idf != 0).astype(float), nTerms)\n",
    "    \n",
    "    def get_norm(self, docs):\n",
    "        vect = CountVectorizer(analyzer='word')\n",
    "        X = vect.fit_transform(docs)\n",
    "        docCount = X.shape[0]\n",
    "\n",
    "        avgFieldLength = X.sum()/float(docCount)\n",
    "        \n",
    "        norm = np.matrix(map(self.decodeNormValue, \n",
    "                             map(self.encodeNormValue, \n",
    "                                 map(self.transform, X.sum(axis = 1))))).reshape(docCount, 1)\n",
    "        \n",
    "        return (norm, avgFieldLength)\n",
    "    \n",
    "    def score(self, query, docs):\n",
    "        query = query.split(' ')\n",
    "        scores = self.execute(query, docs)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ClassicSimilarity(Similarity):\n",
    "    def __init__(self):\n",
    "        Similarity.__init__(self)\n",
    "    \n",
    "        for i in range(256):\n",
    "            self.NORM_TABLE[i] = byte315ToFloat(int(bytes(i)))\n",
    "\n",
    "    def encodeNormValue(self, value):\n",
    "        return floatToByte315(value)\n",
    "    \n",
    "    def get_idf(self, docCount, docFreqs):\n",
    "        idf = 1.0 + np.log(np.divide(docCount, (docFreqs + 1.0)))\n",
    "        return np.square(idf, idf).T\n",
    "    \n",
    "    def get_coord(self, tf, idf):\n",
    "        nTerms = tf.shape[1]\n",
    "        return np.divide((tf != 0).astype(float)*(idf != 0).astype(float), nTerms)\n",
    "    \n",
    "    def transform(self, value):\n",
    "        return 1.0/np.sqrt(value)\n",
    "        \n",
    "    def execute(self, query, docs):\n",
    "        tf, docCount, docFreqs = self.get_tf(docs, query)\n",
    "        idf = self.get_idf(docCount, docFreqs)\n",
    "        tf = tf.sqrt()\n",
    "        coord = self.get_coord(tf, idf)\n",
    "        norm, avgFieldLength = self.get_norm(docs)\n",
    "        queryNorm = np.divide(1.0, np.sqrt(idf.sum(axis = 0)))\n",
    "        # coord * dot(tf * norm, idf * queryNorm)\n",
    "        tf = tf.multiply(norm)\n",
    "        idf = np.multiply(idf, queryNorm)\n",
    "        tfidf = tf.dot(idf)\n",
    "        tfidf = np.multiply(tfidf, coord)\n",
    "        return tfidf\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BM25(Similarity):\n",
    "    def __init__(self, k = 1.2, b = 0.75, coord_factor = False):\n",
    "        Similarity.__init__(self)\n",
    "        self.k = k\n",
    "        self.b = b\n",
    "        self.coord_factor = coord_factor # multiply the scores by the coord factor: \n",
    "                                        # n° query terms in the document / total n° of terms in the query\n",
    "    \n",
    "        for i in range(1, 256):\n",
    "            f = byte315ToFloat(int(bytes(i)))\n",
    "            self.NORM_TABLE[i] = 1.0 / (f*f)\n",
    "        self.NORM_TABLE[0] = 1.0 / self.NORM_TABLE[255]\n",
    "\n",
    "    def encodeNormValue(self, value):\n",
    "        boost = 1.0\n",
    "        return floatToByte315(boost / float(np.sqrt(value)))\n",
    "    \n",
    "    def get_idf(self, docCount, docFreqs):\n",
    "        idf = np.log(1 + np.divide((docCount - docFreqs + 0.5), (docFreqs + 0.5)))\n",
    "        return idf.T\n",
    "    \n",
    "    def transform(self, value):\n",
    "        return value\n",
    "        \n",
    "    def execute(self, query, docs):\n",
    "        tf, docCount, docFreqs = self.get_tf(docs, query)\n",
    "        fieldLengths, avgFieldLength = self.get_norm(docs)\n",
    "        tfNorm = np.divide((tf * (self.k + 1)).toarray(),\n",
    "                           (tf + self.k * (1 - self.b + self.b * (fieldLengths/avgFieldLength))))\n",
    "        idf = self.get_idf(docCount, docFreqs)\n",
    "        if self.coord_factor == True:\n",
    "            coord = self.get_coord(tf, idf)\n",
    "        else:\n",
    "            coord = 1.0\n",
    "        # dot(tf, idf)\n",
    "        tfidf = tfNorm.dot(idf)\n",
    "        return np.multiply(tfidf, coord)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_rank(docs, scores):\n",
    "    candidates = scores != 0\n",
    "    indices = docs.index[np.asarray(candidates.T)[0,:]]\n",
    "    sorted_indices = indices[np.argsort(-np.asarray(scores[indices].T)[0,:])]\n",
    "    for rank, idx in enumerate(sorted_indices):\n",
    "        print \"%d.\\t%s\\t%f\" %(rank, docs[idx], scores[idx, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Some dummies documents\n",
    "docs = pd.Series([\"Lucene Action continue continued\", \"Lucene  Dummies mbuy\", \"Managing Gigabytes\", \n",
    "                  \"Art  Computer Science\", \"Action\", \"Lucene way\", \"Managing Megabytes lucene\", \"Art Gaming\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.\tAction\t1.697623\n",
      "1.\tLucene Action continue continued\t1.585029\n",
      "2.\tLucene way\t0.686408\n",
      "3.\tLucene  Dummies mbuy\t0.556542\n",
      "4.\tManaging Megabytes lucene\t0.556542\n"
     ]
    }
   ],
   "source": [
    "# With no coord factor\n",
    "bm25 = BM25()\n",
    "scores = bm25.score('lucene action', docs)\n",
    "print_rank(docs, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.\tLucene way\t0.686408\n",
      "1.\tLucene Action continue continued\t0.556542\n",
      "2.\tLucene  Dummies mbuy\t0.556542\n",
      "3.\tManaging Megabytes lucene\t0.556542\n"
     ]
    }
   ],
   "source": [
    "scores = bm25.score('lucene', docs)\n",
    "print_rank(docs, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.\tLucene way\t2.460747\n",
      "1.\tLucene Action continue continued\t0.556542\n",
      "2.\tLucene  Dummies mbuy\t0.556542\n",
      "3.\tManaging Megabytes lucene\t0.556542\n"
     ]
    }
   ],
   "source": [
    "scores = bm25.score('lucene way', docs)\n",
    "print_rank(docs, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.\tLucene Action continue continued\t1.585029\n",
      "1.\tAction\t0.848812\n",
      "2.\tLucene way\t0.343204\n",
      "3.\tLucene  Dummies mbuy\t0.278271\n",
      "4.\tManaging Megabytes lucene\t0.278271\n"
     ]
    }
   ],
   "source": [
    "# With coord factor. See w.r.t Out[10]\n",
    "bm25c = BM25(coord_factor = True)\n",
    "scores = bm25c.score('lucene action', docs)\n",
    "print_rank(docs, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = ClassicSimilarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.\tLucene Action continue continued\t1.233349\n",
      "1.\tAction\t0.795332\n",
      "2.\tLucene way\t0.273761\n",
      "3.\tLucene  Dummies mbuy\t0.219009\n",
      "4.\tManaging Megabytes lucene\t0.219009\n"
     ]
    }
   ],
   "source": [
    "scores = tfidf.score('lucene action', docs)\n",
    "print_rank(docs, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.\tLucene way\t0.918752\n",
      "1.\tLucene Action continue continued\t0.735002\n",
      "2.\tLucene  Dummies mbuy\t0.735002\n",
      "3.\tManaging Megabytes lucene\t0.735002\n"
     ]
    }
   ],
   "source": [
    "scores = tfidf.score('lucene', docs)\n",
    "print_rank(docs, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.\tLucene way\t1.751708\n",
      "1.\tLucene Action continue continued\t0.192750\n",
      "2.\tLucene  Dummies mbuy\t0.192750\n",
      "3.\tManaging Megabytes lucene\t0.192750\n"
     ]
    }
   ],
   "source": [
    "scores = tfidf.score('lucene way', docs)\n",
    "print_rank(docs, scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
